<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Writes multiple data records into a delivery stream in a single call,
which can achieve higher throughput per producer than when writing
single records — firehose_put_record_batch • paws</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script href="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script href="../pkgdown.js"></script><meta property="og:title" content="Writes multiple data records into a delivery stream in a single call,
which can achieve higher throughput per producer than when writing
single records — firehose_put_record_batch"><meta property="og:description" content="Writes multiple data records into a delivery stream in a single call,
which can achieve higher throughput per producer than when writing
single records. To write single data records into a delivery stream, use
put_record. Applications using these operations
are referred to as producers.
For information about service quota, see Amazon Kinesis Data Firehose Quota.
Each put_record_batch request supports up
to 500 records. Each record in the request can be as large as 1,000 KB
(before base64 encoding), up to a limit of 4 MB for the entire request.
These limits cannot be changed.
You must specify the name of the delivery stream and the data record
when using put_record. The data record consists
of a data blob that can be up to 1,000 KB in size, and any kind of data.
For example, it could be a segment from a log file, geographic location
data, website clickstream data, and so on.
Kinesis Data Firehose buffers records before delivering them to the
destination. To disambiguate the data blobs at the destination, a common
solution is to use delimiters in the data, such as a newline (\\n) or
some other character unique within the data. This allows the consumer
application to parse individual data items when reading the data from
the destination.
The put_record_batch response includes a
count of failed records, FailedPutCount, and an array of responses,
RequestResponses. Even if the
put_record_batch call succeeds, the value
of FailedPutCount may be greater than 0, indicating that there are
records for which the operation didn't succeed. Each entry in the
RequestResponses array provides additional information about the
processed record. It directly correlates with a record in the request
array using the same ordering, from the top to the bottom. The response
array always includes the same number of records as the request array.
RequestResponses includes both successfully and unsuccessfully
processed records. Kinesis Data Firehose tries to process all records in
each put_record_batch request. A single
record failure does not stop the processing of subsequent records.
A successfully processed record includes a RecordId value, which is
unique for the record. An unsuccessfully processed record includes
ErrorCode and ErrorMessage values. ErrorCode reflects the type of
error, and is one of the following values: ServiceUnavailableException
or InternalFailure. ErrorMessage provides more detailed information
about the error.
If there is an internal server error or a timeout, the write might have
completed or it might have failed. If FailedPutCount is greater than
0, retry the request, resending only those records that might have
failed processing. This minimizes the possible duplicate records and
also reduces the total bytes sent (and corresponding charges). We
recommend that you handle any duplicates at the destination.
If put_record_batch throws
ServiceUnavailableException, back off and retry. If the exception
persists, it is possible that the throughput limits have been exceeded
for the delivery stream.
Data records sent to Kinesis Data Firehose are stored for 24 hours from
the time they are added to a delivery stream as it attempts to send the
records to the destination. If the destination is unreachable for more
than 24 hours, the data is no longer available.
Don't concatenate two or more base64 strings to form the data fields of
your records. Instead, concatenate the raw data, then perform base64
encoding."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="..">paws</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
</li>
<li>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/paws-r/paws/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Writes multiple data records into a delivery stream in a single call,
which can achieve higher throughput per producer than when writing
single records</h1>
    <small class="dont-index">Source: <a href="https://github.com/paws-r/paws/blob/HEAD/R/firehose_operations.R" class="external-link"><code>R/firehose_operations.R</code></a></small>
    <div class="hidden name"><code>firehose_put_record_batch.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Writes multiple data records into a delivery stream in a single call,
which can achieve higher throughput per producer than when writing
single records. To write single data records into a delivery stream, use
<code><a href="firehose_put_record.html">put_record</a></code>. Applications using these operations
are referred to as producers.</p>
<p>For information about service quota, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/limits.html" class="external-link">Amazon Kinesis Data Firehose Quota</a>.</p>
<p>Each <code>put_record_batch</code> request supports up
to 500 records. Each record in the request can be as large as 1,000 KB
(before base64 encoding), up to a limit of 4 MB for the entire request.
These limits cannot be changed.</p>
<p>You must specify the name of the delivery stream and the data record
when using <code><a href="firehose_put_record.html">put_record</a></code>. The data record consists
of a data blob that can be up to 1,000 KB in size, and any kind of data.
For example, it could be a segment from a log file, geographic location
data, website clickstream data, and so on.</p>
<p>Kinesis Data Firehose buffers records before delivering them to the
destination. To disambiguate the data blobs at the destination, a common
solution is to use delimiters in the data, such as a newline (<code>\\n</code>) or
some other character unique within the data. This allows the consumer
application to parse individual data items when reading the data from
the destination.</p>
<p>The <code>put_record_batch</code> response includes a
count of failed records, <code>FailedPutCount</code>, and an array of responses,
<code>RequestResponses</code>. Even if the
<code>put_record_batch</code> call succeeds, the value
of <code>FailedPutCount</code> may be greater than 0, indicating that there are
records for which the operation didn't succeed. Each entry in the
<code>RequestResponses</code> array provides additional information about the
processed record. It directly correlates with a record in the request
array using the same ordering, from the top to the bottom. The response
array always includes the same number of records as the request array.
<code>RequestResponses</code> includes both successfully and unsuccessfully
processed records. Kinesis Data Firehose tries to process all records in
each <code>put_record_batch</code> request. A single
record failure does not stop the processing of subsequent records.</p>
<p>A successfully processed record includes a <code>RecordId</code> value, which is
unique for the record. An unsuccessfully processed record includes
<code>ErrorCode</code> and <code>ErrorMessage</code> values. <code>ErrorCode</code> reflects the type of
error, and is one of the following values: <code>ServiceUnavailableException</code>
or <code>InternalFailure</code>. <code>ErrorMessage</code> provides more detailed information
about the error.</p>
<p>If there is an internal server error or a timeout, the write might have
completed or it might have failed. If <code>FailedPutCount</code> is greater than
0, retry the request, resending only those records that might have
failed processing. This minimizes the possible duplicate records and
also reduces the total bytes sent (and corresponding charges). We
recommend that you handle any duplicates at the destination.</p>
<p>If <code>put_record_batch</code> throws
<code>ServiceUnavailableException</code>, back off and retry. If the exception
persists, it is possible that the throughput limits have been exceeded
for the delivery stream.</p>
<p>Data records sent to Kinesis Data Firehose are stored for 24 hours from
the time they are added to a delivery stream as it attempts to send the
records to the destination. If the destination is unreachable for more
than 24 hours, the data is no longer available.</p>
<p>Don't concatenate two or more base64 strings to form the data fields of
your records. Instead, concatenate the raw data, then perform base64
encoding.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">firehose_put_record_batch</span><span class="op">(</span><span class="va">DeliveryStreamName</span>, <span class="va">Records</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>DeliveryStreamName</dt>
<dd><p>[required] The name of the delivery stream.</p></dd>


<dt>Records</dt>
<dd><p>[required] One or more records.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    

<p>A list with the following syntax:</p>


<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">FailedPutCount =</span> <span class="dv">123</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Encrypted =</span> <span class="cn">TRUE</span><span class="sc">|</span><span class="cn">FALSE</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">RequestResponses =</span> <span class="fu">list</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">RecordId =</span> <span class="st">"string"</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">ErrorCode =</span> <span class="st">"string"</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">ErrorMessage =</span> <span class="st">"string"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre><p></p></div>


    </div>
    <div id="request-syntax">
    <h2>Request syntax</h2>
    


<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>svc<span class="sc">$</span><span class="fu">put_record_batch</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">DeliveryStreamName =</span> <span class="st">"string"</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Records =</span> <span class="fu">list</span>(</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">Data =</span> raw</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre><p></p></div>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by David Kretch, Adam Banker, Dyfan Jones.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer></div>

  


  

  </body></html>

